# -*- coding: utf-8 -*-
"""CV_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18u3t48u0HpeRSyB-55W6kQDoHTFZg0Jz
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
from ipywidgets import interact, FloatSlider, IntSlider   # <-- th√™m d√≤ng n√†y

path_folder = "D:/OneDrive/Ca nhan/Study/Hoc thac si/GenAI - Dai hoc Bach khoa/0. Bo sung kien thuc/5. Thi giac may tinh (IT5409 - Nguyen Thi Oanh)/Bai tap nhom/Proj1.2/Proj1.2/"

# --- 1. H√†m ph√¢n lo·∫°i
def classify_img(img):
    # a. Ki·ªÉm tra ·∫£nh t·ªëi (Bright < 30)
    if np.mean(img) < 30: return "Dark"

    # b. Ki·ªÉm tra nhi·ªÖu mu·ªëi ti√™u (Salt > 8)
    if np.mean(cv2.absdiff(img, cv2.medianBlur(img, 3))) > 8: return "Salt_Pepper"

    # c. Ki·ªÉm tra nhi·ªÖu s·ªçc (1D FFT > 50)
    proj = np.mean(img, axis=0) # Chi·∫øu d·ªçc
    spec = np.abs(np.fft.fft(proj - np.mean(proj)))[1:len(proj)//2]
    if np.max(spec) / (np.mean(spec) + 1e-9) > 50: return "Sinus"

    # d. M·∫∑c ƒë·ªãnh
    return "Standard"

# ====== 1) Image Enhancement (Ch.3) ======
def enhance(img):
    # CLAHE gi√∫p tƒÉng t∆∞∆°ng ph·∫£n tr√™n n·ªÅn nhi·ªÖu h·∫°t
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    eq = clahe.apply(img)
    img = cv2.GaussianBlur(eq, (3,3), 0)
    return img

# ====== 2) Segmentation (Ch.5): Otsu threshold ======
def binarize(img_gray):
    _, th = cv2.threshold(img_gray, 0, 255,
                          cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    # ƒë·∫£o ng∆∞·ª°ng n·∫øu vi·ªÅn (n·ªÅn) ƒëang tr·∫Øng
    border = np.concatenate([th[0,:], th[-1,:], th[:,0], th[:,-1]])
    if np.mean(border) > 127:
        th = cv2.bitwise_not(th)
    return th

# ====== 3) Morphology (Ch.5) ======
def morph(binary):
    # M·ªü (OPEN) nh·∫π ƒë·ªÉ b·ªè nhi·ªÖu nh·ªè
    k_open = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))
    opened = cv2.morphologyEx(binary, cv2.MORPH_OPEN, k_open, iterations=1)

    # ƒê√≥ng (CLOSE) m·∫°nh h∆°n ƒë·ªÉ li·ªÅn khe ƒëen m·∫£nh gi·ªØa h·∫°t
    k_close = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))
    closed = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, k_close, iterations=2)

    return closed


# ====== 4) Split touching grains: Distance Transform + Watershed (Ch.5) ======
def split_watershed(binary, color_img):
    k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))
    sure_bg = cv2.dilate(binary, k, iterations=2)

    dist = cv2.distanceTransform(binary, cv2.DIST_L2, 5)
    dist_norm = cv2.normalize(dist, None, 0, 1.0, cv2.NORM_MINMAX)
    # Ng∆∞·ª°ng tr√™n distance map (tham s·ªë c·∫ßn tinh ch·ªânh n·∫øu over/under-split)
    _, sure_fg = cv2.threshold(dist_norm, 0.35, 1.0, cv2.THRESH_BINARY)
    sure_fg = (sure_fg*255).astype(np.uint8)

    unknown = cv2.subtract(sure_bg, sure_fg)
    _, markers = cv2.connectedComponents(sure_fg)
    markers = markers + 1
    markers[unknown == 255] = 0

    markers = cv2.watershed(color_img.copy(), markers)
    return markers

def gaussian_notch_mask(img, D0=2, centers=[(0,8), (0,-8)]):
    if img.ndim == 3:
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # Bi·∫øn ƒë·ªïi Fourier
    f = np.fft.fft2(img)
    fshift = np.fft.fftshift(f)

    # H√†m t·∫°o m·∫∑t n·∫° Gaussian Notch Reject Filter
    def gaussian_notch_mask(shape, centers, D0=10):
        h, w = shape
        u = np.arange(h)
        v = np.arange(w)
        U, V = np.meshgrid(u - h//2, v - w//2, indexing='ij')
        mask = np.ones((h, w), dtype=np.float32)

        for (cy, cx) in centers:
            Dk = np.sqrt((U - cy)**2 + (V - cx)**2)
            Dk_conj = np.sqrt((U + cy)**2 + (V + cx)**2)
            mask *= (1 - np.exp(-0.5 * (Dk**2 / D0**2))) * (1 - np.exp(-0.5 * (Dk_conj**2 / D0**2)))
        return mask

    # T·∫°o mask cho ƒë√∫ng v·ªã tr√≠ nhi·ªÖu
    mask = gaussian_notch_mask(img.shape, centers, D0=D0)

    # √Åp d·ª•ng m·∫∑t n·∫° v√† bi·∫øn ƒë·ªïi ng∆∞·ª£c
    fshift_filtered = fshift * mask
    f_ishift = np.fft.ifftshift(fshift_filtered)
    img_back = np.fft.ifft2(f_ishift)
    img_back = np.abs(img_back)
    img_back = cv2.normalize(img_back, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)

    return img_back

def show_images(img_list, cmap='gray', figsize=(15, 5)):
    """
    Hi·ªÉn th·ªã danh s√°ch ·∫£nh k√®m ti√™u ƒë·ªÅ.

    Tham s·ªë:
        img_list: list ch·ª©a c√°c ph·∫ßn t·ª≠ d·∫°ng [image, title]
        cmap: b·∫£ng m√†u hi·ªÉn th·ªã (m·∫∑c ƒë·ªãnh 'gray')
        figsize: k√≠ch th∆∞·ªõc to√†n b·ªô figure (m·∫∑c ƒë·ªãnh (15,5))
    """
    n = len(img_list)
    if n == 0:
        print("Danh s√°ch ·∫£nh tr·ªëng!")
        return

    plt.figure(figsize=figsize, facecolor='white')

    plt.figure(figsize=figsize)
    for i, (img, title) in enumerate(img_list, 1):
        plt.subplot(1, n, i)
        # x·ª≠ l√Ω ·∫£nh ph·ª©c n·∫øu c√≥ (nh∆∞ ph·ªï Fourier)
        if np.iscomplexobj(img):
            img = np.log1p(np.abs(img))
        plt.imshow(img, cmap=cmap)
        plt.title(title)
        plt.axis('off')
    plt.tight_layout()
    plt.show()

def binarize_2(img_gray, shift=-30, blur_sigma=1.2, fill_holes=True):
    """
    Binarization v·ªõi ƒëi·ªÅu ch·ªânh ng∆∞·ª°ng c·∫Øt ƒë·ªÉ gi·ªØ t·ªëi ƒëa h·∫°t tr·∫Øng.
    - shift: gi√° tr·ªã d·ªãch ng∆∞·ª°ng Otsu (√¢m => gi·ªØ nhi·ªÅu v√πng s√°ng h∆°n)
    - blur_sigma: l√†m m∆∞·ª£t nh·∫π ƒë·ªÉ tr√°nh t√°ch vi·ªÅn
    - fill_holes: c√≥ l·∫•p l·ªó trong h·∫°t hay kh√¥ng
    """

    # L√†m m∆∞·ª£t nh·∫π ƒë·ªÉ Otsu kh√¥ng b·∫Øt bi√™n r√¨a
    img_blur = cv2.GaussianBlur(img_gray, (0, 0), blur_sigma)

    # T√≠nh ng∆∞·ª°ng Otsu
    val, _ = cv2.threshold(img_blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    new_thresh = max(0, min(255, val + shift))  # ƒëi·ªÅu ch·ªânh ng∆∞·ª°ng

    # √Åp d·ª•ng ng∆∞·ª°ng m·ªõi
    _, th = cv2.threshold(img_blur, new_thresh, 255, cv2.THRESH_BINARY)

    # ƒê·∫£o ng∆∞·ª°ng n·∫øu vi·ªÅn (n·ªÅn) ƒëang tr·∫Øng
    border = np.concatenate([th[0,:], th[-1,:], th[:,0], th[:,-1]])
    if np.mean(border) > 127:
        th = cv2.bitwise_not(th)

    # L·∫•p l·ªó nh·ªè b√™n trong h·∫°t n·∫øu c·∫ßn
    if fill_holes:
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        th = cv2.morphologyEx(th, cv2.MORPH_CLOSE, kernel, iterations=2)

    return th

def split_watershed(binary, color_img,
                    erode_ksize=7, erode_iter=1,     # ‚Üì tƒÉng n·∫øu c√≤n t√°ch ƒë√¥i
                    bg_dilate_iter=1):
    # Chu·∫©n ho√°
    if binary.dtype != np.uint8:
        binary = (binary > 0).astype(np.uint8)*255
    if color_img.ndim == 2:
        color_img = cv2.cvtColor(color_img, cv2.COLOR_GRAY2BGR)
    color_img = color_img.astype(np.uint8)

    k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (erode_ksize, erode_ksize))

    # >>> seed b·∫±ng erosion thay v√¨ threshold distance <<<
    sure_fg = cv2.erode(binary, k, iterations=erode_iter)      # l√µi h·∫°t ‚Üí 1 seed/h·∫°t

    sure_bg = cv2.dilate(binary, k, iterations=bg_dilate_iter)  # n·ªÅn n·ªü nh·∫π ƒë·ªÉ c√≥ "unknown"
    unknown = cv2.subtract(sure_bg, sure_fg)

    # markers int32
    _, markers = cv2.connectedComponents(sure_fg)
    markers = markers.astype(np.int32) + 1
    markers[unknown == 255] = 0

    markers = cv2.watershed(color_img, markers)
    return markers

def enhance_contrast(img, bg_ksize=81, clahe_clip=2.0, clahe_grid=(8,8)):
  # 1) v·ªÅ x√°m
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if img.ndim==3 else img.copy()

    # 2) Flat-field: ∆∞·ªõc l∆∞·ª£ng n·ªÅn b·∫±ng blur l·ªõn r·ªìi tr·ª´ ƒëi
    #   (medianBlur ·ªïn v·ªõi chi ti·∫øt ‚Äúh·∫°t g·∫°o‚Äù m·∫£nh)
    bg = cv2.medianBlur(gray, bg_ksize)        # th·ª≠ 81 / 101 t√πy k√≠ch th∆∞·ªõc ·∫£nh
    flat = cv2.normalize(gray.astype(np.float32) - bg.astype(np.float32),
                         None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)

    # 3) CLAHE ƒë·ªÉ k√©o t∆∞∆°ng ph·∫£n c·ª•c b·ªô (gi√∫p v√πng tr√™n s√°ng l√™n)
    clahe = cv2.createCLAHE(clipLimit=clahe_clip, tileGridSize=clahe_grid)
    out = clahe.apply(flat)

    # 4) L√†m m∆∞·ª£t r·∫•t nh·∫π ƒë·ªÉ ƒë·ªìng nh·∫•t ƒë·ªô s√°ng b√™n trong h·∫°t
    out = cv2.GaussianBlur(out, (3,3), 0.5)
    return out

    return out

img_name = "1_wIXlvBeAFtNVgJd49VObgQ.png"
raw = cv2.imdecode(np.fromfile(path_folder + img_name, dtype=np.uint8),
                   cv2.IMREAD_COLOR)
gray = cv2.cvtColor(raw, cv2.COLOR_BGR2GRAY)

show_images([
    [raw, "·∫¢nh g·ªëc"],
    [gray, "·∫¢nh chuy·ªÉn sang Grayscale"]
])

img = gray

# --- Demo hi·ªÉn th·ªã ---
img_filtered = gaussian_notch_mask(img)

# Hi·ªÉn th·ªã 3 ·∫£nh: G·ªëc - Ph·ªï - Sau x·ª≠ l√Ω
f = np.fft.fftshift(np.fft.fft2(img))

show_images([
    [img, "·∫¢nh gray"],
    [np.log1p(np.abs(f)), "Ph·ªï Fourier (log)"],
    [img_filtered, "·∫¢nh sau khi x·ª≠ l√Ω"]
])

enhanced = enhance(img)

show_images([
    [raw, "·∫¢nh g·ªëc"],
    [img_filtered, "·∫¢nh sau khi x·ª≠ l√Ω Fourier"],
    [enhanced, "·∫¢nh sau khi x·ª≠ l√Ω"]
])

img = enhanced

enh = enhance_contrast(img)

# --- T√≠nh histogram ---
hist_ori = cv2.calcHist([img], [0], None, [256], [0,256]).flatten()
hist_enh = cv2.calcHist([enh], [0], None, [256], [0,256]).flatten()

# --- Hi·ªÉn th·ªã ---
plt.figure(figsize=(12, 8))

plt.subplot(2,2,1)
plt.imshow(raw, cmap='gray')
plt.title("·∫¢nh g·ªëc")
plt.axis('off')

plt.subplot(2,2,2)
plt.imshow(enh, cmap='gray')
plt.title("·∫¢nh sau enhance_contrast")
plt.axis('off')

plt.subplot(2,2,3)
plt.plot(hist_ori)
plt.title("Histogram ·∫£nh g·ªëc")
plt.xlabel("Gi√° tr·ªã m·ª©c x√°m (0‚Äì255)")
plt.ylabel("S·ªë l∆∞·ª£ng pixel (log scale)")
plt.yscale('log')

plt.subplot(2,2,4)
plt.plot(hist_enh)
plt.title("Histogram sau x·ª≠ l√Ω (log Y)")
plt.xlabel("Gi√° tr·ªã m·ª©c x√°m (0‚Äì255)")
plt.ylabel("S·ªë l∆∞·ª£ng pixel (log scale)")
plt.yscale('log')

plt.tight_layout()
plt.show()

img = enh

binary = binarize(img)
# binary = binarize(enh)

show_images([
    [raw, "·∫¢nh g·ªëc"],
    [binary, "·∫¢nh nh·ªã ph√¢n (Otsu)"]
])

img = binary

k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (4,4))
opened_vis = cv2.morphologyEx(binary, cv2.MORPH_OPEN, k, iterations=1)
morphed = morph(img)

# ====== Hi·ªÉn th·ªã ======

show_images([
    [binary, "·∫¢nh nh·ªã ph√¢n (Otsu)"],
    [opened_vis, "Opened (l·ªçc nhi·ªÖu nh·ªè)"],
    [morphed, "Closed (l√†m li·ªÅn v√πng)"]
])

img = morphed

# 1) G·ªçi watershed
markers = split_watershed(binary=img, color_img=raw)

# 2) ·∫¢nh overlay bi√™n (ranh gi·ªõi = -1) l√™n ·∫£nh g·ªëc
overlay = cv2.cvtColor(raw.copy(), cv2.COLOR_BGR2RGB)
overlay[markers == -1] = [255, 0, 0]   # ranh gi·ªõi t√¥ ƒë·ªè

# 3) T·∫°o ·∫£nh g√°n m√†u cho t·ª´ng nh√£n h·∫°t (>=2)
label_vis = np.zeros_like(overlay)     # RGB
grain_labels = [lab for lab in np.unique(markers) if lab > 1]

# T·∫°o b·∫£ng m√†u ng·∫´u nhi√™n nh∆∞ng c·ªë ƒë·ªãnh ƒë·ªÉ t√°i l·∫≠p
rng = np.random.default_rng(42)
colors = {lab: rng.integers(0, 256, size=3, dtype=np.uint8) for lab in grain_labels}

for lab in grain_labels:
    label_vis[markers == lab] = colors[lab]
# t√¥ ranh gi·ªõi ƒë·ªè cho d·ªÖ nh√¨n
label_vis[markers == -1] = [255, 0, 0]

count = len(grain_labels)


# Hi·ªÉn th·ªã s·ªë
markers = split_watershed(binary=morphed, color_img=raw)

# T√¥ ranh gi·ªõi (pixels c√≥ gi√° tr·ªã -1)
overlay[markers == -1] = [255, 0, 0]

# L·∫•y danh s√°ch nh√£n h·∫°t (b·ªè n·ªÅn v√† bi√™n)
grain_labels = [lab for lab in np.unique(markers) if lab > 1]

# L·∫•y t√¢m (centroid) c·ªßa m·ªói h·∫°t
centroids = []
for lab in grain_labels:
    ys, xs = np.where(markers == lab)
    if len(xs) > 0 and len(ys) > 0:
        cx, cy = int(np.mean(xs)), int(np.mean(ys))
        centroids.append((lab, cx, cy))

# 5S·∫Øp x·∫øp th·ª© t·ª±: t·ª´ tr√™n xu·ªëng, tr√°i sang ph·∫£i (y tr∆∞·ªõc, r·ªìi x)
centroids_sorted = sorted(centroids, key=lambda c: (c[2] // 50, c[1]))

# V·∫Ω s·ªë th·ª© t·ª±
for idx, (lab, cx, cy) in enumerate(centroids_sorted, start=1):
    cv2.putText(overlay, str(idx), (cx-10, cy+10),
                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)

# 4) Hi·ªÉn th·ªã
show_images([
    [label_vis, f"Markers colorized ‚Ä¢ #h·∫°t = {count}"],
    [overlay, f"ƒê·∫øm s·ªë ‚Ä¢ #h·∫°t = {count}"]
])

import cv2
import numpy as np
import os

# --- 1. C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N & NG∆Ø·ª†NG ---
path_folder = "D:/OneDrive/Ca nhan/Study/Hoc thac si/GenAI - Dai hoc Bach khoa/0. Bo sung kien thuc/5. Thi giac may tinh (IT5409 - Nguyen Thi Oanh)/Bai tap nhom/Proj1.2/Proj1.2/"

# C√°c ng∆∞·ª°ng ƒë√£ ch·ªët
TH_BRIGHT = 30.0
TH_SALT = 8.0
TH_FFT = 50.0

def calculate_metrics(img_path):
    # ƒê·ªçc ·∫£nh
    stream = open(img_path, "rb")
    bytes = bytearray(stream.read())
    numpyarray = np.asarray(bytes, dtype=np.uint8)
    img = cv2.imdecode(numpyarray, cv2.IMREAD_GRAYSCALE)
    stream.close()

    if img is None: return None

    # --- THAM S·ªê 1: BRIGHTNESS (ƒê·ªô s√°ng TB) ---
    bright = np.mean(img)

    # --- THAM S·ªê 2: SALT SCORE (Nhi·ªÖu mu·ªëi ti√™u) ---
    # L·∫•y ·∫£nh g·ªëc tr·ª´ ƒëi ·∫£nh ƒë√£ l·ªçc Median ƒë·ªÉ t√¨m ra c√°c h·∫°t nhi·ªÖu
    denoised = cv2.medianBlur(img, 3)
    diff = cv2.absdiff(img, denoised)
    salt = np.mean(diff)

    # --- THAM S·ªê 3: 1D FFT SCORE (Ph√°t hi·ªán s·ªçc/Sinus) ---
    # √âp ·∫£nh th√†nh 1 ƒë∆∞·ªùng t√≠n hi·ªáu (trung b√¨nh c·ªôt)
    proj = np.mean(img, axis=0)

    # Bi·∫øn ƒë·ªïi Fourier tr√™n ƒë∆∞·ªùng t√≠n hi·ªáu n√†y
    proj_detrend = proj - np.mean(proj) # Lo·∫°i b·ªè th√†nh ph·∫ßn DC
    spectrum = np.abs(np.fft.fft(proj_detrend))

    # L·∫•y n·ª≠a ph·ªï (b·ªè t·∫ßn s·ªë 0)
    valid_spec = spectrum[1:len(spectrum)//2]

    # T√≠nh t·ª∑ l·ªá: ƒê·ªânh cao nh·∫•t / Trung b√¨nh n·ªÅn
    if len(valid_spec) > 0:
        fft_score = np.max(valid_spec) / (np.mean(valid_spec) + 1e-9)
    else:
        fft_score = 0

    return bright, salt, fft_score

def classify_image(bright, salt, fft_score):
    # Logic ∆∞u ti√™n theo y√™u c·∫ßu
    if bright < TH_BRIGHT:
        return "·∫¢nh t·ªëi (Dark)"

    # ∆Øu ti√™n check nhi·ªÖu s·ªçc v√† mu·ªëi ti√™u
    if fft_score > TH_FFT:
        return "Nhi·ªÖu s·ªçc (Sinus)"

    if salt > TH_SALT:
        return "Nhi·ªÖu mu·ªëi ti√™u (Salt_Pepper)"

    # C√≤n l·∫°i
    return "·∫¢nh chu·∫©n (Standard)"

# --- CH·∫†Y V√Ä IN B·∫¢NG K·∫æT QU·∫¢ ---
print(f"ƒêang x·ª≠ l√Ω th∆∞ m·ª•c: {path_folder}\n")

# Header b·∫£ng
print(f"{'T√äN FILE':<55} | {'BRIGHT':<8} | {'SALT':<8} | {'1D FFT':<8} | {'-> K·∫æT LU·∫¨N'}")
print("-" * 110)

valid_extensions = ['.png', '.jpg', '.jpeg']
files = [f for f in os.listdir(path_folder) if os.path.splitext(f)[1].lower() in valid_extensions]
files.sort()

for file_name in files:
    full_path = os.path.join(path_folder, file_name)
    metrics = calculate_metrics(full_path)

    if metrics:
        b, s, f = metrics
        # L·∫•y k·∫øt lu·∫≠n d·ª±a tr√™n th√¥ng s·ªë
        result = classify_image(b, s, f)

        # In ra m√†n h√¨nh
        print(f"{file_name:<55} | {b:<8.2f} | {s:<8.2f} | {f:<8.2f} | {result}")
    else:
        print(f"{file_name:<55} | ERROR READING FILE")

import cv2
import numpy as np
import matplotlib.pyplot as plt

def process_full_pipeline(img_input):
    """
    H√†m pipeline t·ªïng h·ª£p:
    1. Input -> gaussian_notch_mask -> enhance -> binarize -> morph -> split_watershed
    2. Th·ª±c hi·ªán visualize (t√¥ m√†u h·∫°t, v·∫Ω bi√™n ƒë·ªè, ƒë√°nh s·ªë th·ª© t·ª±)
    """

    # --- B∆Ø·ªöC 1: ƒê·ªåC ·∫¢NH V√Ä CHU·∫®N B·ªä ---
    if isinstance(img_input, str):
        # ƒê·ªçc ·∫£nh t·ª´ ƒë∆∞·ªùng d·∫´n (h·ªó tr·ª£ ti·∫øng Vi·ªát)
        stream = open(img_input, "rb")
        bytes = bytearray(stream.read())
        numpyarray = np.asarray(bytes, dtype=np.uint8)
        raw = cv2.imdecode(numpyarray, cv2.IMREAD_COLOR)
        if raw is None:
            print(f"L·ªói: Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh t·ª´ {img_input}")
            return
        gray = cv2.cvtColor(raw, cv2.COLOR_BGR2GRAY)
    else:
        # Input l√† ·∫£nh d·∫°ng numpy array
        raw = img_input
        if raw.ndim == 3:
            gray = cv2.cvtColor(raw, cv2.COLOR_BGR2GRAY)
        else:
            gray = raw
            raw = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR) # T·∫°o gi·∫£ ·∫£nh m√†u ƒë·ªÉ v·∫Ω overlay

    # --- B∆Ø·ªöC 2: G·ªåI C√ÅC H√ÄM X·ª¨ L√ù TU·∫¶N T·ª∞ ---
    print("1. ƒêang kh·ª≠ nhi·ªÖu s·ªçc (Notch Filter)...")
    img_notch = gaussian_notch_mask(gray)

    print("2. ƒêang tƒÉng c∆∞·ªùng ·∫£nh (Enhance)...")
    img_enh = enhance(img_notch)

    print("3. ƒêang nh·ªã ph√¢n h√≥a (Binarize)...")
    img_bin = binarize(img_enh)

    print("4. ƒêang x·ª≠ l√Ω h√¨nh th√°i h·ªçc (Morph)...")
    img_morph = morph(img_bin)

    print("5. ƒêang t√°ch h·∫°t (Watershed)...")
    # L∆∞u √Ω: split_watershed c·∫ßn ·∫£nh nh·ªã ph√¢n (ƒë√£ morph) v√† ·∫£nh g·ªëc m√†u
    markers = split_watershed(binary=img_morph, color_img=raw)


    # --- B∆Ø·ªöC 3: VISUALIZATION (Logic c·ªßa b·∫°n) ---

    # 3.1) ·∫¢nh overlay bi√™n (ranh gi·ªõi = -1) l√™n ·∫£nh g·ªëc
    overlay = cv2.cvtColor(raw.copy(), cv2.COLOR_BGR2RGB) # Chuy·ªÉn sang RGB ƒë·ªÉ hi·ªÉn th·ªã plt ƒë√∫ng m√†u
    overlay[markers == -1] = [255, 0, 0]   # Ranh gi·ªõi t√¥ ƒë·ªè

    # 3.2) T·∫°o ·∫£nh g√°n m√†u cho t·ª´ng nh√£n h·∫°t (>=2)
    label_vis = np.zeros_like(overlay)     # N·ªÅn ƒëen
    grain_labels = [lab for lab in np.unique(markers) if lab > 1] # B·ªè 0 (unknown) v√† 1 (n·ªÅn)

    # T·∫°o b·∫£ng m√†u ng·∫´u nhi√™n c·ªë ƒë·ªãnh
    rng = np.random.default_rng(42)
    colors = {lab: rng.integers(0, 256, size=3, dtype=np.uint8) for lab in grain_labels}

    for lab in grain_labels:
        label_vis[markers == lab] = colors[lab]

    # T√¥ ranh gi·ªõi ƒë·ªè cho d·ªÖ nh√¨n tr√™n ·∫£nh label
    label_vis[markers == -1] = [255, 0, 0]

    count = len(grain_labels)

    # 3.3) T√≠nh to√°n t√¢m h·∫°t v√† S·∫Øp x·∫øp
    centroids = []
    for lab in grain_labels:
        ys, xs = np.where(markers == lab)
        if len(xs) > 0 and len(ys) > 0:
            cx, cy = int(np.mean(xs)), int(np.mean(ys))
            centroids.append((lab, cx, cy))

    # S·∫Øp x·∫øp th·ª© t·ª±: t·ª´ tr√™n xu·ªëng (chia block 50px), tr√°i sang ph·∫£i
    # (c[2] l√† y, c[1] l√† x)
    centroids_sorted = sorted(centroids, key=lambda c: (c[2] // 50, c[1]))

    # 3.4) V·∫Ω s·ªë th·ª© t·ª± l√™n ·∫£nh Overlay
    for idx, (lab, cx, cy) in enumerate(centroids_sorted, start=1):
        cv2.putText(overlay, str(idx), (cx - 10, cy + 5),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2, cv2.LINE_AA)

    # --- B∆Ø·ªöC 4: HI·ªÇN TH·ªä ---
    print(f"‚úÖ Ho√†n th√†nh! T√¨m th·∫•y {count} h·∫°t.")

    # S·ª≠ d·ª•ng h√†m show_images c√≥ s·∫µn c·ªßa b·∫°n
    show_images([
        [label_vis, f"Ph√¢n v√πng m√†u ‚Ä¢ {count} h·∫°t"],
        [overlay, f"K·∫øt qu·∫£ cu·ªëi c√πng (ƒê√°nh s·ªë)"]
    ], figsize=(12, 6))

    return markers, count

# ƒê∆∞·ªùng d·∫´n ·∫£nh
img_path = path_folder + "1_wIXlvBeAFtNVgJd49VObgQ.png"

# G·ªçi h√†m
markers, rice_count = process_full_pipeline(img_path)

import cv2
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path


# ================= 1. C√ÅC H√ÄM C√îNG C·ª§ (DEFINITIONS) =================

def load_image(path):
    """ƒê·ªçc ·∫£nh h·ªó tr·ª£ ƒë∆∞·ªùng d·∫´n ti·∫øng Vi·ªát"""
    p = Path(path)
    if not p.exists(): return None, None
    raw = cv2.imdecode(np.fromfile(str(p), dtype=np.uint8), cv2.IMREAD_COLOR)
    gray = cv2.cvtColor(raw, cv2.COLOR_BGR2GRAY)
    return raw, gray


def classify_img(img_gray):
    """Ph√¢n lo·∫°i ·∫£nh ƒë·ªÉ ƒë∆∞a ra quy·∫øt ƒë·ªãnh x·ª≠ l√Ω"""
    # a. ·∫¢nh t·ªëi
    if np.mean(img_gray) < 30: return "Dark"

    # b. Nhi·ªÖu mu·ªëi ti√™u (so s√°nh ·∫£nh g·ªëc v·ªõi ·∫£nh l√†m m∆∞·ª£t)
    if np.mean(cv2.absdiff(img_gray, cv2.medianBlur(img_gray, 3))) > 8: return "Salt_Pepper"

    # c. Nhi·ªÖu s·ªçc (Sinus) b·∫±ng FFT 1D
    proj = np.mean(img_gray, axis=0)
    spec = np.abs(np.fft.fft(proj - np.mean(proj)))[1:len(proj) // 2]
    if np.max(spec) / (np.mean(spec) + 1e-9) > 50: return "Sinus"

    # d. M·∫∑c ƒë·ªãnh
    return "Standard"


def apply_fft_notch(img_gray, D0=2, centers=[(0, 8), (0, -8)]):
    """L·ªçc nhi·ªÖu s·ªçc b·∫±ng Fourier"""
    f = np.fft.fft2(img_gray)
    fshift = np.fft.fftshift(f)
    h, w = img_gray.shape
    y, x = np.ogrid[:h, :w]
    cy, cx = h // 2, w // 2

    mask = np.ones((h, w), dtype=np.float32)
    for (my, mx) in centers:  # my, mx: kho·∫£ng c√°ch t·ª´ t√¢m
        # T·∫°o 2 l·ªó ƒëen ƒë·ªëi x·ª©ng qua t√¢m
        for sign in [1, -1]:
            d2 = (y - (cy + sign * my)) ** 2 + (x - (cx + sign * mx)) ** 2
            mask *= (1 - np.exp(-0.5 * (d2 / (D0 ** 2))))

    fshift_filtered = fshift * mask
    img_back = np.fft.ifft2(np.fft.ifftshift(fshift_filtered))
    return cv2.normalize(np.abs(img_back), None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)


def enhance_contrast(img_gray, clahe_clip=2.0, use_median=False):
    """TƒÉng t∆∞∆°ng ph·∫£n & Clean n·ªÅn"""
    img = img_gray.copy()
    if use_median:
        img = cv2.medianBlur(img, 5)  # Kh·ª≠ nhi·ªÖu mu·ªëi ti√™u tr∆∞·ªõc

    # Tr·ª´ n·ªÅn (Flat field)
    bg = cv2.medianBlur(img, 81)
    diff = img.astype(np.float32) - bg.astype(np.float32)
    flat = cv2.normalize(diff, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)

    # CLAHE
    clahe = cv2.createCLAHE(clipLimit=clahe_clip, tileGridSize=(8, 8))
    out = clahe.apply(flat)
    return cv2.GaussianBlur(out, (3, 3), 0.5)

def enhance(img):
    # CLAHE gi√∫p tƒÉng t∆∞∆°ng ph·∫£n tr√™n n·ªÅn nhi·ªÖu h·∫°t
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    eq = clahe.apply(img)
    img = cv2.GaussianBlur(eq, (3,3), 0)
    return img



def binarize(img_enhanced, shift=-30):
    """Ph√¢n ng∆∞·ª°ng Otsu c√≥ d·ªãch chuy·ªÉn (shift)"""
    # Blur nh·∫π ƒë·ªÉ Otsu ·ªïn ƒë·ªãnh
    blur = cv2.GaussianBlur(img_enhanced, (0, 0), 1.2)
    val, _ = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

    # D·ªãch ng∆∞·ª°ng
    new_thresh = np.clip(val + shift, 0, 255)
    _, th = cv2.threshold(blur, new_thresh, 255, cv2.THRESH_BINARY)

    # ƒê·∫£o m√†u n·∫øu n·ªÅn tr·∫Øng
    border_mean = np.mean(np.concatenate([th[0, :], th[-1, :], th[:, 0], th[:, -1]]))
    if border_mean > 127: th = cv2.bitwise_not(th)

    # L·∫•p l·ªó trong h·∫°t
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
    return cv2.morphologyEx(th, cv2.MORPH_CLOSE, kernel, iterations=2)


def morph_clean(binary_img):
    """L√†m s·∫°ch v√† n·ªëi li·ªÅn"""
    k_open = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
    opened = cv2.morphologyEx(binary_img, cv2.MORPH_OPEN, k_open, iterations=1)

    k_close = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
    closed = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, k_close, iterations=2)
    return closed


def split_watershed(binary_img, raw_img_color):
    """T√°ch h·∫°t d√≠nh nhau"""
    k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))
    sure_fg = cv2.erode(binary_img, k, iterations=1)
    sure_bg = cv2.dilate(binary_img, k, iterations=1)
    unknown = cv2.subtract(sure_bg, sure_fg)

    _, markers = cv2.connectedComponents(sure_fg)
    markers = markers.astype(np.int32) + 1
    markers[unknown == 255] = 0

    markers = cv2.watershed(raw_img_color, markers)
    return markers


def visualize(raw, markers, title="Result"):
    """V·∫Ω k·∫øt qu·∫£ ƒë·∫øm"""
    overlay = raw.copy()
    labels = [lab for lab in np.unique(markers) if lab > 1]

    centroids = []
    for lab in labels:
        ys, xs = np.where(markers == lab)
        if len(xs) > 0:
            centroids.append((lab, int(np.mean(xs)), int(np.mean(ys))))

    centroids.sort(key=lambda c: (c[2] // 50, c[1]))

    overlay[markers == -1] = [0, 0, 255]  # Bi√™n ƒë·ªè
    for idx, (_, cx, cy) in enumerate(centroids, 1):
        cv2.putText(overlay, str(idx), (cx - 10, cy),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

    plt.figure(figsize=(12, 6))
    plt.subplot(1, 2, 1);
    plt.imshow(cv2.cvtColor(raw, cv2.COLOR_BGR2RGB));
    plt.title("Original")
    plt.subplot(1, 2, 2);
    plt.imshow(cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB));
    plt.title(f"{title} - Count: {len(labels)}")
    plt.show()


# ================= 2. PIPELINE X·ª¨ L√ù (LOGIC CH√çNH) =================

def process_pipeline(img_path):
    # 1. Load ·∫£nh
    raw, gray = load_image(img_path)
    if raw is None: print("L·ªói load ·∫£nh"); return

    # 2. Ph√¢n lo·∫°i ·∫£nh
    img_type = classify_img(gray)
    print(f"üîç Ph√¢n lo·∫°i ·∫£nh: [ {img_type} ]")

    # 3. ƒêI·ªÄU H∆Ø·ªöNG X·ª¨ L√ù (IF - ELSE)
    enhanced = None
    binary = None

    if img_type == "Sinus":
        # -> Quy tr√¨nh cho ·∫£nh s·ªçc
        print(" -> Ch·∫°y kh·ª≠ s·ªçc FFT...")
        fft_cleaned = apply_fft_notch(gray)
        enhanced = enhance_contrast(fft_cleaned)
        binary = binarize(enhanced, shift=-30)

    elif img_type == "Dark":
        # -> Quy tr√¨nh cho ·∫£nh t·ªëi
        print(" -> Ch·∫°y tƒÉng s√°ng m·∫°nh...")
        # TƒÉng clahe_clip l√™n 5.0 ƒë·ªÉ k√©o s√°ng
        enhanced = enhance_contrast(gray, clahe_clip=5.0)
        # Shift th·∫•p h∆°n (-40) ƒë·ªÉ gi·ªØ l·∫°i nhi·ªÅu chi ti·∫øt
        binary = binarize(enhanced, shift=-40)

    elif img_type == "Salt_Pepper":
        # -> Quy tr√¨nh cho ·∫£nh nhi·ªÖu h·∫°t
        print(" -> Ch·∫°y kh·ª≠ nhi·ªÖu Median...")
        enhanced = enhance_contrast(gray, use_median=True)
        binary = binarize(enhanced, shift=-25)

    else:  # Standard
        # -> Quy tr√¨nh m·∫∑c ƒë·ªãnh
        print(" -> Ch·∫°y m·∫∑c ƒë·ªãnh...")
        enhanced = enhance_contrast(gray)
        binary = binarize(enhanced, shift=-30)

    # 4. C√°c b∆∞·ªõc chung (Morphology + Watershed)
    morphed = morph_clean(binary)
    markers = split_watershed(morphed, raw)

    # 5. Hi·ªÉn th·ªã
    visualize(raw, markers, title=f"Type: {img_type}")


# ================= 3. CH·∫†Y TH·ª¨ =================
folder = r"D:/OneDrive/Ca nhan/Study/Hoc thac si/GenAI - Dai hoc Bach khoa/0. Bo sung kien thuc/5. Thi giac may tinh (IT5409 - Nguyen Thi Oanh)/Bai tap nhom/Proj1.2/Proj1.2/"
img_name = "1_wIXlvBeAFtNVgJd49VObgQ.png"

# G·ªçi 1 h√†m duy nh·∫•t
process_pipeline(folder + img_name)